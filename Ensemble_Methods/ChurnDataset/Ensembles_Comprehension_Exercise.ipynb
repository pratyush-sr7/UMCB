{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIEb3H8DUnjy"
   },
   "source": [
    "# Task 1 - Data Preparation\n",
    "For this task, you will perform the following steps:\n",
    "- Load all the necessary packages for this exercise\n",
    "- Load the data\n",
    "- Split the data into input features and the target variable\n",
    "- Split the data into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a82e79ad"
   },
   "outputs": [],
   "source": [
    "# Import 'numpy' and 'pandas' to work with numbers and dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import 'matplotlib.pyplot' for visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import method for train-validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import methods for building decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Importing packages for building ensemble models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Import 'GridSearchCV' for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import suitable performance metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_score, precision_recall_curve, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "a251d675",
    "outputId": "80cb8cc4-9d84-459c-a381-5ecf6d003770",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data and take a look at it\n",
    "# Note: Make sure that the data is in the same folder as the Jupyter notebook or specify the address correctly\n",
    "churndata = pd.read_csv('churndata_DT.csv', index_col = 'customerID')\n",
    "churndata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1572d3ad"
   },
   "outputs": [],
   "source": [
    "# Split the data into input features and the target variable\n",
    "# Note: The target variable here is the 'Churn' feature\n",
    "X = ########## CODE HERE ##########\n",
    "y = ########## CODE HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation datasets using the 'train_test_split' method\n",
    "# Hint: Study the documentation of the 'train_test_split' method\n",
    "# Note: Use 'test_size = 0.3' and 'random_state = 0'\n",
    "X_train, X_val, y_train, y_val = ########## CODE HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Building Classification Models\n",
    "For this task, you will perform the following steps:\n",
    "\n",
    "- Part 1\n",
    "  - Build and analyze a random forest model for the data with:\n",
    "    - Default parameters\n",
    "    - Hyperparameter tuning using *GridSearchCV()* on:\n",
    "        - n_estimators\n",
    "        - combination of n_estimators and max_depth\n",
    "\n",
    "- Part 2\n",
    "  - Build and analyze a LightGBM model for the data with:\n",
    "    - Default parameters\n",
    "    - Hyperparameter tuning using *GridSearchCV()* on combination of n_estimators, max_depth and learning_rate\n",
    "\n",
    "- Part 3\n",
    "  - Build and analyze a decision tree model for the data pruned using the *ccp_alpha* parameter\n",
    "    - The best *ccp_alpha* parameter has been provided to you for this exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Random Forest Models\n",
    "\n",
    "### Sub-task 1 - Random Forest Model - I\n",
    "\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a random forest model for the data using the *RandomForestClassifier()* method with the default parameters\n",
    "- Visualize the confusion matrices for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier for the data using the 'RandomForestClassifier()' method\n",
    "# Hint: Study the documentation of the 'RandomForestClassifier()' method\n",
    "# Note: Use the default values for all parameters\n",
    "# Note: Use 'random_state = 0'\n",
    "rf1 = ########## CODE HERE ##########\n",
    "rf1 = rf1.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'rf1' on the training and validation data\n",
    "# Hint: Study the documentation of the 'ConfusionMatrixDisplay.from_estimator()' method\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(rf1, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(rf1, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-task 2 - Random Forest Model - II\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a random forest model for the data using the *RandomForestClassifier()* method and tune it on the number of estimators parameter using the *GridSearchCV()* method\n",
    "- Visualize the confusion matrices for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a basic random forest object using the 'RandomForestClassifier()' method\n",
    "# Hint: Study the documentation of the 'RandomForestClassifier()' method\n",
    "# Note: Use 'random_state = 0'\n",
    "base_rf_model = ########## CODE HERE ##########\n",
    "\n",
    "# Define the range of the 'n_estimators' parameter and store it in a parameter grid dictionary\n",
    "parameters_grid = {'n_estimators': np.arange(50, 300, 50)}\n",
    "\n",
    "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
    "# Hint: Study the documentation of the 'GridSearchCV()' method\n",
    "# Hint: The 'estimator' parameter should be set to the base random forest model on which tuning is to be performed\n",
    "# Hint: The 'param_grid' parameter should be set to the grid of parameters on which tuning is to be performed\n",
    "# Note: Use 'scoring = roc_auc' and 'cv = 2'\n",
    "grid = GridSearchCV(########## CODE HERE ##########)\n",
    "\n",
    "# Train a model using the training data\n",
    "# Note: Execution times for grid searches are exponentially proportional to the number of hyperparameters being tuned for\n",
    "# Note: This cell might take a few minutes to run\n",
    "rf2 = grid.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimal value of 'n_estimators' obtained from 'rf2'\n",
    "# Hint: Use the 'best_params_' attribute of the 'rf2' object and look for 'n_estimators'\n",
    "best_n_estimators = ########## CODE HERE ##########\n",
    "\n",
    "print('The optimal value of n_estimators is', best_n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'rf2' on the training and validation data\n",
    "# Hint: Study the documentation of the 'ConfusionMatrixDisplay.from_estimator()' method\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(rf2, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(rf2, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-task 3 - Random Forest Model - III\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a random forest model for the data using the *RandomForestClassifier()* method and tune it on the number of estimators and the maximum tree depth parameters using the *GridSearchCV()* method\n",
    "- Visualize the confusion matrices for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a basic random forest object using the 'RandomForestClassifier()' method\n",
    "# Hint: Study the documentation of the 'RandomForestClassifier()' method\n",
    "# Note: Use 'random_state = 0'\n",
    "base_rf_model = ########## CODE HERE ##########\n",
    "\n",
    "# Define the range of the 'n_estimators' and the 'max_depth' parameters and store them in a parameter grid dictionary\n",
    "parameters_grid = {'n_estimators': np.arange(50, 300, 50), 'max_depth': np.arange(2, 8, 1)}\n",
    "\n",
    "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
    "# Hint: Study the documentation of the 'GridSearchCV()' method\n",
    "# Hint: The 'estimator' parameter should be set to the base random forest model on which tuning is to be performed\n",
    "# Hint: The 'param_grid' parameter should be set to the grid of parameters on which tuning is to be performed\n",
    "# Note: Use 'scoring = roc_auc' and 'cv = 2'\n",
    "grid = GridSearchCV(########## CODE HERE ##########)\n",
    "\n",
    "# Train a model using the training data\n",
    "# Note: Execution times for grid searches are exponentially proportional to the number of hyperparameters being tuned for\n",
    "# Note: This cell might take a few minutes to run\n",
    "rf3 = grid.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimal value of 'n_estimators' and 'max_depth' obtained from 'rf3'\n",
    "# Hint: Use the 'best_params_' attribute of the 'rf3' object and look for 'n_estimators' and 'max_depth'\n",
    "best_n_estimators = ########## CODE HERE ##########\n",
    "best_max_depth = ########## CODE HERE ##########\n",
    "\n",
    "print('The optimal value of n_estimators is', best_n_estimators)\n",
    "print('The optimal value of max_depth is', best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'rf3' on the training and validation data\n",
    "# Hint: Study the documentation of the 'ConfusionMatrixDisplay.from_estimator()' method\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(rf3, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(rf3, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtyurRP9Vzci"
   },
   "source": [
    "## Part 2 - Gradient Boosted Tree Models\n",
    "### Sub-task 1 - Gradient Boosted Tree Model - I\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a gradient boosted tree model for the data using the *LGBMClassifier()* method with the default parameters\n",
    "- Visualize the confusion matrices for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTtL1pJ8JPhx",
    "outputId": "c90cef52-b347-41fe-c0b7-a71267a27763"
   },
   "outputs": [],
   "source": [
    "# Create a gradient boosted tree classifier for the data using the 'LGBMClassifier()' method\n",
    "# Hint: Study the documentation of the 'LGBMClassifier()' method\n",
    "# Note: Use the default values for all parameters\n",
    "# Note: Use 'random_state = 0'\n",
    "gbt1 = ########## CODE HERE ##########\n",
    "gbt1 = gbt1.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'gbt1' on the training and validation data\n",
    "# Hint: Study the documentation of the 'ConfusionMatrixDisplay.from_estimator()' method\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(gbt1, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(gbt1, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-task 2 - Gradient Boosted Tree Model - II\n",
    "For this sub-task, you will perform the following steps:\n",
    "- Build a gradient boosted tree model for the data using the *LGBMClassifier()* method and tune it on the number of estimators, maximum tree depth and learning rate parameters using the *GridSearchCV()* method\n",
    "- Visualize the confusion matrices for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a basic gradient boosted tree object using the 'LGBMClassifier()' method\n",
    "# Hint: Study the documentation of the 'LGBMClassifier()' method\n",
    "# Note: Use 'random_state = 0'\n",
    "base_gbt_model = ########## CODE HERE ##########\n",
    "\n",
    "# Define the range of the 'n_estimators', the 'max_depth' and the 'learning_rate' parameters and store them in a parameter grid dictionary\n",
    "parameters_grid = {'n_estimators': np.arange(50, 300, 50),\n",
    "                   'max_depth': np.arange(2, 8, 1),\n",
    "                   'learning_rate': np.arange(0.005, 0.03, 0.005)}\n",
    "\n",
    "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
    "# Hint: Study the documentation of the 'GridSearchCV()' method\n",
    "# Hint: The 'estimator' parameter should be set to the base gradient boosted tree model on which tuning is to be performed\n",
    "# Hint: The 'param_grid' parameter should be set to the grid of parameters on which tuning is to be performed\n",
    "# Note: Use 'scoring = roc_auc' and 'cv = 2'\n",
    "grid = GridSearchCV(########## CODE HERE ##########)\n",
    "\n",
    "# Train a model using the training data\n",
    "# Note: Execution times for grid searches are exponentially proportional to the number of hyperparameters being tuned for\n",
    "# Note: This cell might take a few minutes to run\n",
    "gbt2 = grid.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimal value of 'n_estimators', 'max_depth' and 'learning_rate' obtained from 'gbt2'\n",
    "# Hint: Use the 'best_params_' attribute of the 'gbt2' object and look for 'n_estimators', 'max_depth' and 'learning_rate'\n",
    "best_n_estimators = ########## CODE HERE ##########\n",
    "best_max_depth = ########## CODE HERE ##########\n",
    "best_learning_rate = ########## CODE HERE ##########\n",
    "\n",
    "print('The optimal value of n_estimators is', best_n_estimators)\n",
    "print('The optimal value of learning_rate is', best_learning_rate)\n",
    "print('The optimal value of max_depth is', best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'gbt2' on the training and validation data\n",
    "# Hint: Study the documentation of the 'ConfusionMatrixDisplay.from_estimator()' method\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(gbt2, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(gbt2, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Decision Tree Model\n",
    "For this task, you will build a decision tree model for the data using the *DecisionTreeClassifier()* method and prune it using the *ccp_alpha* parameter. Note that the optimal value of *ccp_alpha* for this data set is provided to you for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree model on the training data using the 'DecisionTreeClassifier()' method with the best 'ccp_alpha' value\n",
    "# Hint: Study the documentation of the 'DecisionTreeClassifier()' method\n",
    "# Hint: The optimal value of 'ccp_alpha' for the data is 0.0018\n",
    "# Note: Use 'random_state = 0'\n",
    "DT = ########## CODE HERE ##########\n",
    "DT = DT.fit(########## CODE HERE ##########)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrices for 'DT' on the training and validation data\n",
    "# Hint: Study the documentation of the 'ConfusionMatrixDisplay.from_estimator()' method\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(DT, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
    "ConfusionMatrixDisplay.from_estimator(DT, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
    "ax[0].set_title('Training')\n",
    "ax[1].set_title('Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Comparing the Models\n",
    "For this task, you will perform the following steps:\n",
    "- Compare various classification performance metrics for the six tree models that you have built\n",
    "- Compare the ROC curves for these six models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print various classification performance measures for all the models on the training and validation data\n",
    "# Hint: You will need to obtain the predicted class labels for each of the models using the 'predict()' method\n",
    "# Hint: You will need to obtain the predicted probabilities for each of the models using the 'predict_proba()' method\n",
    "\n",
    "# Hint: Study the documentations of the different peformance metrics methods\n",
    "# Note: For sensitivity, precision, and F1 score, specify the 'pos_label' parameter as '1' or leave it at the default value\n",
    "# Note: For specificity, specify the 'pos_label' parameter as '0'\n",
    "\n",
    "# Compute predicted probabilities and class labels for each of the models on the training and validation data\n",
    "# Hint: The second column of the matrix returned by the 'predict_proba()' method contains the positive class probabilities\n",
    "\n",
    "models = [rf1, rf2, rf3, gbt1, gbt2, DT]\n",
    "modelnames = ['rf1', 'rf2', 'rf3', 'gbt1', 'gbt2', 'DT']\n",
    "\n",
    "train_probabilities = [None] * len(models)\n",
    "val_probabilities = [None] * len(models)\n",
    "train_y_pred = [None] * len(models)\n",
    "val_y_pred = [None] * len(models)\n",
    "\n",
    "i = -1\n",
    "for model in models:\n",
    "    i = i + 1\n",
    "    train_probabilities[i] = models[i].########## CODE HERE ##########\n",
    "    val_probabilities[i] = models[i].########## CODE HERE ##########\n",
    "    train_y_pred[i] = models[i].########## CODE HERE ##########\n",
    "    val_y_pred[i] = models[i].########## CODE HERE ##########\n",
    "\n",
    "# Use the predicted class labels to compute the following performance metrics\n",
    "\n",
    "# Compute the accuracies\n",
    "train_acc = [None] * len(models)\n",
    "val_acc = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_acc[i] = accuracy_score(########## CODE HERE ##########)\n",
    "    val_acc[i] = accuracy_score(########## CODE HERE ##########)\n",
    "\n",
    "# Compute the sensitivities\n",
    "train_sens = [None] * len(models)\n",
    "val_sens = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_sens[i] = recall_score(########## CODE HERE ##########)\n",
    "    val_sens[i] = recall_score(########## CODE HERE ##########)\n",
    "\n",
    "# Compute the specificities\n",
    "train_spec = [None] * len(models)\n",
    "val_spec = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_spec[i] = recall_score(########## CODE HERE ##########)\n",
    "    val_spec[i] = recall_score(########## CODE HERE ##########)\n",
    "\n",
    "# Compute the precisions\n",
    "train_prec = [None] * len(models)\n",
    "val_prec = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_prec[i] = precision_score(########## CODE HERE ##########)\n",
    "    val_prec[i] = precision_score(########## CODE HERE ##########)\n",
    "\n",
    "# Compute the F1 scores\n",
    "train_f1 = [None] * len(models)\n",
    "val_f1 = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_f1[i] = f1_score(########## CODE HERE ##########)\n",
    "    val_f1[i] = f1_score(########## CODE HERE ##########)\n",
    "\n",
    "# Use the predicted probabilities to compute the ROC AUC scores\n",
    "\n",
    "# Compute the ROC AUC scores\n",
    "train_auc = [None] * len(models)\n",
    "val_auc = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_auc[i] = roc_auc_score(########## CODE HERE ##########)\n",
    "    val_auc[i] = roc_auc_score(########## CODE HERE ##########)\n",
    "\n",
    "# Summarize the above metrics for all the models using a single data frame and display it\n",
    "modelcompare = pd.DataFrame(data = {'Training Accuracy': train_acc,\n",
    "                                    'Validation Accuracy': val_acc,\n",
    "                                    'Training Sensitivity': train_sens,\n",
    "                                    'Validation Sensitivity': val_sens,\n",
    "                                    'Training Specificity': train_spec,\n",
    "                                    'Validation Specificity': val_spec,\n",
    "                                    'Training Precision': train_prec,\n",
    "                                    'Validation Precision': val_prec,\n",
    "                                    'Training F1 Score': train_f1,\n",
    "                                    'Validation F1 Score': val_f1,\n",
    "                                    'Training ROC AUC Score': train_auc,\n",
    "                                    'Validation ROC AUC Score': val_auc},\n",
    "                            index = modelnames)\n",
    "\n",
    "modelcompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the ROC curves of the models on the training and validation data\n",
    "\n",
    "# Obtain the values for (1 - specificity) and sensitivity for the training and validation data using the 'roc_curve()' method for all the models\n",
    "# Hint: Study the documentation of the 'roc_curve()' method\n",
    "# Note: Specify the 'pos_label' as '1' or leave it at the default value\n",
    "train_1_spec = [None] * len(models)\n",
    "train_sens = [None] * len(models)\n",
    "val_1_spec = [None] * len(models)\n",
    "val_sens = [None] * len(models)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    train_1_spec[i], train_sens[i], _ = roc_curve(########## CODE HERE ##########)\n",
    "    val_1_spec[i], val_sens[i], _ = roc_curve(########## CODE HERE ##########)\n",
    "\n",
    "# Plot the ROC curves for all the models for the training and the validation data\n",
    "plt.figure(figsize = (12, 4))\n",
    "colorlist = ['red', 'blue', 'green', 'orange', 'maroon', 'purple']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    sns.lineplot(x = train_1_spec[i], y = train_sens[i], color = colorlist[i], label = '_nolegend_', ci = None)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Training ROC Curves')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in np.arange(0, len(models), 1):\n",
    "    sns.lineplot(x = val_1_spec[i], y = val_sens[i], color = colorlist[i], label = modelnames[i], ci = None)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Validation ROC Curves')\n",
    "plt.legend(bbox_to_anchor = [1, 1])\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Misclassification Costs of Suitable Model\n",
    "For this task, you will perform the following steps:\n",
    "- Select a model based on their classification performance measures\n",
    "- Compute the baseline misclassification cost\n",
    "- Observe how the misclassification cost varies as the cut-off for classification is increased\n",
    "- Obtain the best misclassification cost and the associated cut-off from the training data\n",
    "- Compute the potentially best misclassification cost of the model using the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Suppose that the problem statement requires that your classification model satisfies the following conditions:\n",
    "- The absolute value of the difference between the training and the validation accuracies is less than 0.1\n",
    "- The validation accuracy is greater than 0.75\n",
    "- The absolute value of the difference between the training and the validation ROC AUC scores is less than 0.1\n",
    "- The validation ROC AUC score is greater than 0.75\n",
    "- The validation sensitivity is greater than 0.65\n",
    "- The validation precision is greater than 0.7\n",
    "- The validation F1 score is greater than 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the conditions on the performance measures as given above, select the best model\n",
    "# Hint: Use the 'modelcompare' data frame that you created to obtain the name of the best model\n",
    "best_model_name = modelcompare[########## CODE HERE ##########].index[0]\n",
    "\n",
    "print('The most suitabel model according to the conditions of the problem statement is \"{}\".'.format(best_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the cost of false positives and false negatives\n",
    "# Note: The cost of false positives and false negatives are provided to you for this exercise\n",
    "# Note: Labeling a 'not churn' customer as 'churn' leads to a few follow up phone calls only, so its cost is less\n",
    "# Note: Labeling a 'churn' customer as 'not churn' may lead to the loss of that customer, so its cost is more\n",
    "fp_cost = 50\n",
    "fn_cost = 100\n",
    "print('The cost of classifying a person as churn when they are not a churn = {} dollars'.format(fp_cost))\n",
    "print('The cost of classifying a person as not churn when they are a churn = {} dollars'.format(fn_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the misclassification cost for the naive model on the training and the validation data\n",
    "# Hint: The naive model in this case would classify everyone as a churn or class '1'\n",
    "# Hint: That means all class '1' people are classified as class '1' accurately\n",
    "# Hint: The class '0' people are the only ones that contribute to the misclassification\n",
    "# Hint: So, you need to count how many 'y_train' and 'y_val' values are actually class '0', since all of them are labeled as class '1'\n",
    "# Hint: Recall the formula for the misclassification cost\n",
    "train_mc_cost_0 = ########## CODE HERE ##########\n",
    "val_mc_cost_0 = ########## CODE HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the misclassification cost of classifying everyone as a churn\n",
    "print('The misclassification cost of classifying everyone in the training data as a churn = {} dollars'.format(train_mc_cost_0))\n",
    "print('The misclassification cost of classifying everyone in the validation data as a churn = {} dollars'.format(val_mc_cost_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the confusion matrices for the selected model using the 'confusion_matrix()' method for the training and the validation data\n",
    "# Hint: Study the documentation of the 'confusion_matrix()' method\n",
    "train_cf = confusion_matrix(########## CODE HERE ##########)\n",
    "val_cf = confusion_matrix(########## CODE HERE ##########)\n",
    "\n",
    "# Obtain the number of false positives and false negatives from the confusion matrices 'train_cf' and 'val_cf'\n",
    "# Hint: Study the documentation of the 'confusion_matrix()' method\n",
    "train_fp_count = ########## CODE HERE ##########\n",
    "train_fn_count = ########## CODE HERE ##########\n",
    "val_fp_count = ########## CODE HERE ##########\n",
    "val_fn_count = ########## CODE HERE ##########\n",
    "\n",
    "# Calculate and print the misclassification costs for the selected model for the training and the validation datasets\n",
    "# Hint: Recall the formula for the misclassification cost\n",
    "train_mc_cost = ########## CODE HERE ##########\n",
    "val_mc_cost = ########## CODE HERE ##########\n",
    "print('The misclassification cost on the training data of using the selected model with default cut-off = {} dollars'.format(train_mc_cost))\n",
    "print('The misclassification cost on the validation data of using the selected model with default cut-off = {} dollars'.format(val_mc_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of misclassification costs for various cut-off values for the selected model on the training and the validation data\n",
    "# Hint: If the 'train_probabilities' or the 'val_probabilities' value is greater than the cut-off, then the label is class '1', else it's class '0'\n",
    "# Hint: Try using the 'np.where()' method to obtain the predictions for each cut-off value\n",
    "train_mc_cost = []\n",
    "val_mc_cost = []\n",
    "cutoffs = np.arange(0, 1, 0.01)\n",
    "for cutoff in cutoffs:\n",
    "    train_y_pred_curr = ########## CODE HERE ##########\n",
    "    train_curr_cf = confusion_matrix(########## CODE HERE ##########)\n",
    "    train_fp_count = ########## CODE HERE ##########\n",
    "    train_fn_count = ########## CODE HERE ##########\n",
    "    train_mc_cost_current = ########## CODE HERE ##########\n",
    "    train_mc_cost.append(train_mc_cost_current)\n",
    "    \n",
    "    val_y_pred_curr = ########## CODE HERE ##########\n",
    "    val_curr_cf = confusion_matrix(########## CODE HERE ##########)\n",
    "    val_fp_count = ########## CODE HERE ##########\n",
    "    val_fn_count = ########## CODE HERE ##########\n",
    "    val_mc_cost_current = ########## CODE HERE ##########\n",
    "    val_mc_cost.append(val_mc_cost_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a graph to show how the misclassification costs vary as the cut-off is increased for the training and the validation data\n",
    "sns.lineplot(x = cutoffs, y = train_mc_cost, color = 'blue', label = 'Training', ci = None)\n",
    "sns.lineplot(x = cutoffs, y = val_mc_cost, color = 'red', label = 'Validation', ci = None)\n",
    "plt.xlabel('Cut-off')\n",
    "plt.ylabel('Misclassification Cost in dollars')\n",
    "plt.title('Misclassification Cost for the Model')\n",
    "plt.legend(bbox_to_anchor = [1, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain and print the best misclassification cost for the selected model on the training data\n",
    "# Hint: The best misclassification cost would be the minimum cost\n",
    "train_best_cost = ########## CODE HERE ##########\n",
    "\n",
    "# Obtain and print the best cut-off cost for the selected model on the training data\n",
    "# Hint: The best cut-off is the cut-off value for which the misclassification cost is the least\n",
    "train_best_cutoff = ########## CODE HERE ##########\n",
    "\n",
    "print('Best classification cut-off probability from the training data for the selected model = {}'.format(train_best_cutoff))\n",
    "print('Best misclassification cost on the training data for the selected model = {} dollars'.format(train_best_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cut-off associated with the best misclassification cost on the training data to get the best cost for the validation data\n",
    "# Hint: The expected best misclassification cost on the validation data is the cost associated with the best cut-off from the training data\n",
    "val_best_cost = ########## CODE HERE ##########\n",
    "\n",
    "print('Best misclassification cost on the validation data for the selected model = {} dollars'.format(val_best_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
