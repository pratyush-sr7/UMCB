{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdKzDBtRUXSy"
      },
      "source": [
        "# Part 1 - Introduction and Data Description\n",
        "\n",
        "For this demonstration, we will use a bank marketing data set. A bank ran a marketing campaign in the past and has obtained data pertaining to nearly 45,000 customers, which includes variables such as their age, jobs, bank balance, education, loan status and so on. The bank wants to develop its future strategies based on the insights that it drew from the previous campaign and improve for the next campaign so that more customers agree to open term deposits with the bank.\n",
        "\n",
        "Here, ***y*** (whether the customer wishes to open a deposit or not) is the target variable. A ***yes*** in the ***y*** column indicates that the campaign was successful and the customer agreed to open a term deposit account with the bank. In contrast, a ***no*** in the ***y*** column indicates that the campaign was not very successful and the customer could not be convinced to open a term deposit account.\n",
        "\n",
        "The purpose of this demonstration is to show the learner how to build and implement random forest models and gradient boosted tree models for classification. We will also look at how model performance varies for different values of various hyperparameters.\n",
        "\n",
        "## Data description\n",
        "\n",
        "### Input features\n",
        "- ***age*** : Age of the customer (numeric)\n",
        "- ***job*** : Type of job (categorical)\n",
        "- ***marital*** : Marital status (categorical)\n",
        "- ***education***: Level of education (categorical)\n",
        "- ***default***: Does the customer have a credit default or not? (categorical: *no*, *yes*, *unknown*)\n",
        "- ***balance***: Bank balance of the customer (numeric)\n",
        "- ***housing***: Does the customer have a housing loan or not? (categorical: *no*, *yes*, *unknown*)\n",
        "- ***loan***: Does the customer have a personal loan or not? (categorical: *no*, *yes*, *unknown*)\n",
        "- ***contact***: Contact communication type (categorical)\n",
        "- ***day***: Last contact day of the week (categorical)\n",
        "- ***month***: Last contact month of year (categorical)\n",
        "- ***duration***: Last contact duration, in seconds (numeric)\n",
        "- ***campaign***: Number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "- ***pdays***: Number of days that passed by after the client was last contacted from a previous campaign (numeric)\n",
        "- ***previous***: Number of contacts performed before this campaign and for this client (numeric)\n",
        "- ***poutcome***: Outcome of the previous marketing campaign (categorical)\n",
        "\n",
        "### Output feature\n",
        "- ***y***: Has the client subscribed a term deposit? (categorical: ***yes***, ***no***)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ViPVs4sOxQQ"
      },
      "outputs": [],
      "source": [
        "# Import 'numpy' and 'pandas' for working with numbers and data frames\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import 'matplotlib.pyplot' and 'seaborn' for visualizations\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import packages for building ensemble models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier \n",
        "\n",
        "# Import method for train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import sutiable error measure methods\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n",
        "\n",
        "# Import 'GridSearchCV' for hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub7eLnfcO_wa"
      },
      "outputs": [],
      "source": [
        "# Import the raw data\n",
        "url = 'https://raw.githubusercontent.com/liyemaumd/data/main/bank.csv'\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ewY3GSgTh0s"
      },
      "outputs": [],
      "source": [
        "# Take a look at the data\n",
        "##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfPuRDj6ZuGI"
      },
      "outputs": [],
      "source": [
        "# Discard features not used for the analysis\n",
        "df = df[['age', 'duration', 'balance', 'job', 'marital', 'education', 'y']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHN0F3gXZuGJ"
      },
      "outputs": [],
      "source": [
        "# Generate dummy variables for categorical features\n",
        "df_dummies = ##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R2ba8oxZuGJ"
      },
      "outputs": [],
      "source": [
        "# Take a look at the data with the new dummy variables\n",
        "##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnQeDU9BYNf_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Take a look at the new dummy variables\n",
        "for col in df_dummies.columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8FwyHPAZuGK"
      },
      "outputs": [],
      "source": [
        "# Select a few features for the purpose of demonstration\n",
        "df_dummies = df_dummies[['age', 'duration', 'balance',\n",
        "                         'job_management', 'job_retired', 'job_services', 'job_student',\n",
        "                         'marital_divorced', 'marital_married', 'marital_single',\n",
        "                         'education_primary', 'education_secondary', 'education_tertiary',\n",
        "                         'y_yes']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLhsa8BXVbtW"
      },
      "outputs": [],
      "source": [
        "# Split the data into input and output\n",
        "X = ##### CODE HERE #####\n",
        "y = ##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xQ_ARrLZuGL"
      },
      "outputs": [],
      "source": [
        "# Divide the data into training and validation sets\n",
        "# Use 20% of the data as validation\n",
        "# Set the random state parameter to 123\n",
        "X_train, X_val, y_train, y_val = ##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47KQwnd5ZuGL"
      },
      "source": [
        "# Part 2 - Random Forest\n",
        "We will now fit a random forest model to the data and study the performance of the model on the training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJdnHXbKWLlD"
      },
      "outputs": [],
      "source": [
        "# Create a random forest classifier model\n",
        "# Use 100 estimators, a maximum tree depth of 5, and set the class weight as 'balanced'\n",
        "# Set the random state parameter to 123\n",
        "rf = ##### CODE HERE #####\n",
        "\n",
        "# Fit the model to the training data\n",
        "##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej5IIlgAZuGM"
      },
      "outputs": [],
      "source": [
        "# Obtain feature importances from the model\n",
        "rfimp = ##### CODE HERE #####\n",
        "rfimp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyjee1JSsTzd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Visualize the feature importances\n",
        "plt.figure(figsize = (6, 4))\n",
        "rfimpdf = pd.DataFrame(data = {'Features': X_train.columns, 'Importances': rfimp})\n",
        "rfimpdf = rfimpdf.sort_values(by = 'Importances', ascending = False)\n",
        "sns.barplot(data = rfimpdf, x = 'Importances', y = 'Features', orient = 'h');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jemi_rOZuGN"
      },
      "outputs": [],
      "source": [
        "# Display the confusion matrices for the model on the training and validation data\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
        "ConfusionMatrixDisplay.from_estimator(rf, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
        "ConfusionMatrixDisplay.from_estimator(rf, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
        "ax[0].set_title('Training')\n",
        "ax[1].set_title('Validation');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFo33UW6ZuGN"
      },
      "outputs": [],
      "source": [
        "# Compute the accuracy scores on the training and validation data\n",
        "# Obtain predictions\n",
        "y_pred_train = ##### CODE HERE #####\n",
        "y_pred_val = ##### CODE HERE #####\n",
        "\n",
        "# Compute accuracy scores\n",
        "train_acc = ##### CODE HERE #####\n",
        "val_acc = ##### CODE HERE #####\n",
        "\n",
        "print('Accuracy on the training data = {}'.format(train_acc))\n",
        "print('Accuracy on the validation data = {}'.format(val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6EI2fg3ZuGN"
      },
      "outputs": [],
      "source": [
        "# Compute the ROC AUC scores for the training and the validation data\n",
        "# Obtain predicted probabilities for class '1'\n",
        "train_probabilities = ##### CODE HERE #####\n",
        "val_probabilities = ##### CODE HERE #####\n",
        "\n",
        "# Compute ROC AUC scores\n",
        "train_auc = ##### CODE HERE #####\n",
        "val_auc = ##### CODE HERE #####\n",
        "\n",
        "print('ROC AUC score for the training data = {}'.format(train_auc))\n",
        "print('ROC AUC score for the validation data = {}'.format(val_auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78RWIA9AZuGN"
      },
      "source": [
        "# Part 3 - Random Forest: Hyperparameter Tuning\n",
        "In this section, we will:\n",
        "- Tune the random forest model for the following hyperparameters:\n",
        "  - Number of estimators\n",
        "  - Maximum tree depth\n",
        "- Tune the random forest model for a combination of number of estimators and maximum tree depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxyMFuNkZuGO"
      },
      "source": [
        "## Subpart 1 - Hyperparameter Tuning: Number of Estimators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqQBdujEZuGO"
      },
      "outputs": [],
      "source": [
        "# Define a list of number of estimators to tune over\n",
        "num_estimators = np.arange(50, 550, 50)\n",
        "\n",
        "# Create and train a random forest model for each value of number of estimators\n",
        "performance_df = pd.DataFrame(data = None)\n",
        "\n",
        "# Use a for loop to loop over the different models and capture their performances\n",
        "indexcount = -1\n",
        "for current_num_estimators in num_estimators:\n",
        "    indexcount = indexcount + 1\n",
        "    \n",
        "    # Create a random forest model with the current specifications\n",
        "    # Use the current number of estimators, a maximum tree depth of 5, and set the class weight as 'balanced'\n",
        "    # Set the random state parameter to 123\n",
        "    current_rf = ##### CODE HERE #####\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    ##### CODE HERE #####\n",
        "    \n",
        "    print('\\n Training for {} estimators is complete'.format(current_num_estimators))\n",
        "    \n",
        "    # Obtain predictions\n",
        "    current_y_pred_train = ##### CODE HERE #####\n",
        "    current_y_pred_val = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute accuracy scores\n",
        "    current_train_acc = ##### CODE HERE #####\n",
        "    current_val_acc = ##### CODE HERE #####\n",
        "    \n",
        "    # Obtain predicted probabilities for class '1'\n",
        "    current_train_probabilities = ##### CODE HERE #####\n",
        "    current_val_probabilities = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute ROC AUC scores\n",
        "    current_train_auc = ##### CODE HERE #####\n",
        "    current_val_auc = ##### CODE HERE #####\n",
        "    \n",
        "    tempdf = pd.DataFrame(index = [indexcount],\n",
        "                          data = {'Number of Estimators': current_num_estimators,\n",
        "                                  'Training Accuracy': current_train_acc,\n",
        "                                  'Validation Accuracy': current_val_acc,\n",
        "                                  'Training ROC AUC': current_train_auc,\n",
        "                                  'Validation ROC AUC': current_val_auc})\n",
        "    \n",
        "    performance_df = pd.concat([performance_df, tempdf])\n",
        "\n",
        "performance_df.set_index('Number of Estimators')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPsKF_ojZuGO"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation accuracy scores with respect to number of estimators\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Number of Estimators', y = 'Validation Accuracy', marker = 'o', markersize = 12)\n",
        "plt.title('Validation Accuracy Scores by Number of Estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.xticks(num_estimators);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC3CZ842ZuGP"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation ROC AUC scores with respect to number of estimators\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Number of Estimators', y = 'Validation ROC AUC', marker = 'o', markersize = 12)\n",
        "plt.title('Validation ROC AUC Scores by Number of Estimators')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.xticks(num_estimators);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX1hRtZLZuGP"
      },
      "source": [
        "## Subpart 2 - Hyperparameter Tuning: Maximum Tree Depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0CAQoyGZuGP"
      },
      "outputs": [],
      "source": [
        "# Define a list of maximum tree depth values to tune over\n",
        "max_tree_depths = np.arange(1, 11, 1)\n",
        "\n",
        "# Create and train a random forest model for each value of maximum tree depth\n",
        "performance_df = pd.DataFrame(data = None)\n",
        "\n",
        "# Use a for loop to loop over the different models and capture their performances\n",
        "indexcount = -1\n",
        "for current_max_tree_depth in max_tree_depths:\n",
        "    indexcount = indexcount + 1\n",
        "    \n",
        "    # Create a random forest model with the current specifications\n",
        "    # Use 100 estimators, the current maximum tree depth, and set the class weight as 'balanced'\n",
        "    # Set the random state parameter to 123\n",
        "    current_rf = ##### CODE HERE #####\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    ##### CODE HERE #####\n",
        "    \n",
        "    print('\\n Training for tree depth of {} is complete'.format(current_max_tree_depth))\n",
        "    \n",
        "    # Obtain predictions\n",
        "    current_y_pred_train = ##### CODE HERE #####\n",
        "    current_y_pred_val = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute accuracy scores\n",
        "    current_train_acc = ##### CODE HERE #####\n",
        "    current_val_acc = ##### CODE HERE #####\n",
        "    \n",
        "    # Obtain predicted probabilities for class '1'\n",
        "    current_train_probabilities = ##### CODE HERE #####\n",
        "    current_val_probabilities = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute ROC AUC scores\n",
        "    current_train_auc = ##### CODE HERE #####\n",
        "    current_val_auc = ##### CODE HERE #####\n",
        "    \n",
        "    tempdf = pd.DataFrame(index = [indexcount],\n",
        "                          data = {'Maximum Tree Depth': current_max_tree_depth,\n",
        "                                  'Training Accuracy': current_train_acc,\n",
        "                                  'Validation Accuracy': current_val_acc,\n",
        "                                  'Training ROC AUC': current_train_auc,\n",
        "                                  'Validation ROC AUC': current_val_auc})\n",
        "    \n",
        "    performance_df = pd.concat([performance_df, tempdf])\n",
        "\n",
        "performance_df.set_index('Maximum Tree Depth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHFGmFjIZuGP"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation accuracy scores with respect to maximum tree depth\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Maximum Tree Depth', y = 'Validation Accuracy', marker = 'o', markersize = 12)\n",
        "plt.title('Validation Accuracy Scores by Maximum Tree Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Maximum Tree Depth')\n",
        "plt.xticks(max_tree_depths);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUGfxpB2ZuGQ"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation ROC AUC scores with respect to maximum tree depth\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Maximum Tree Depth', y = 'Validation ROC AUC', marker = 'o', markersize = 12)\n",
        "plt.title('Validation ROC AUC Scores by Maximum Tree Depth')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.xlabel('Maximum Tree Depth')\n",
        "plt.xticks(max_tree_depths);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCdDcqdlZuGQ"
      },
      "source": [
        "## Subpart 3 - Hyperparameter Tuning: Combinations of Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ecQv7asLZuGQ"
      },
      "outputs": [],
      "source": [
        "# Initialize a basic random forest classifier model\n",
        "# Set the class weight as 'balanced'\n",
        "# Set the random state parameter to 123\n",
        "base_grid_model = ##### CODE HERE #####\n",
        "\n",
        "# Define a range of hyperparameter values to tune for and store them in a dictionary\n",
        "parameters_grid = {'n_estimators': [100, 200],\n",
        "                   'max_depth': [5, 7]}\n",
        "\n",
        "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
        "# Use ROC AUC score as a scoring metric\n",
        "# Use the default number of cross-validation folds\n",
        "# Set the 'verbose' parameter to 3 or more to display useful results during the process\n",
        "grid = ##### CODE HERE #####\n",
        "\n",
        "# Fit the model on the training data\n",
        "grid_model = ##### CODE HERE #####\n",
        "\n",
        "# Print the optimal values of 'n_estimators' and 'max_depth'\n",
        "best_n_estimators = grid_model.best_params_['n_estimators']\n",
        "best_max_depth = grid_model.best_params_['max_depth']\n",
        "best_roc_auc_score = grid_model.best_score_\n",
        "\n",
        "print('\\n The optimal model has {} estimators, each of maximum tree depth {}, and it has an ROC AUC score of {}.'.format(best_n_estimators, best_max_depth, best_roc_auc_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtyurRP9Vzci"
      },
      "source": [
        "# Part 4 - Gradient Boosted Tree\n",
        "We will now fit a gradient boosted tree model to the data and study the performance of the model on the training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdHUiiYgZuGQ"
      },
      "outputs": [],
      "source": [
        "# Create a gradient boosted tree classifier model\n",
        "# Use 100 estimators, a maximum tree depth of 5, a learning rate of 0.1, and set the class weight as 'balanced'\n",
        "# Set the random state parameter to 123\n",
        "gbt = ##### CODE HERE #####\n",
        "\n",
        "# Fit the model to the training data\n",
        "##### CODE HERE #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCXy1P5yZuGR"
      },
      "outputs": [],
      "source": [
        "# Obtain feature importances from the model\n",
        "gbtimp = ##### CODE HERE #####\n",
        "gbtimp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3iJe_WgZuGR"
      },
      "outputs": [],
      "source": [
        "# Visualize the feature importances\n",
        "plt.figure(figsize = (6, 4))\n",
        "gbtimpdf = pd.DataFrame(data = {'Features': X_train.columns, 'Importances': gbtimp})\n",
        "gbtimpdf = gbtimpdf.sort_values(by = 'Importances', ascending = False)\n",
        "sns.barplot(data = gbtimpdf, x = 'Importances', y = 'Features', orient = 'h');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9H2GEzHZuGR"
      },
      "outputs": [],
      "source": [
        "# Display the confusion matrices for the model on the training and validation data\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "fig, ax = plt.subplots(1, 2, figsize = (12, 4))\n",
        "ConfusionMatrixDisplay.from_estimator(gbt, X_train, y_train, cmap = plt.cm.Blues, ax = ax[0])\n",
        "ConfusionMatrixDisplay.from_estimator(gbt, X_val, y_val, cmap = plt.cm.Blues, ax = ax[1])\n",
        "ax[0].set_title('Training')\n",
        "ax[1].set_title('Validation');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIlFwKkpZuGR"
      },
      "outputs": [],
      "source": [
        "# Compute the accuracy scores on the training and validation data\n",
        "# Obtain predictions\n",
        "y_pred_train = ##### CODE HERE #####\n",
        "y_pred_val = ##### CODE HERE #####\n",
        "\n",
        "# Compute accuracy scores\n",
        "train_acc = ##### CODE HERE #####\n",
        "val_acc = ##### CODE HERE #####\n",
        "\n",
        "print('Accuracy on the training data = {}'.format(train_acc))\n",
        "print('Accuracy on the validation data = {}'.format(val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgcfruZPZuGS"
      },
      "outputs": [],
      "source": [
        "# Compute the ROC AUC scores for the training and the validation data\n",
        "# Obtain predicted probabilities for class '1'\n",
        "train_probabilities = ##### CODE HERE #####\n",
        "val_probabilities = ##### CODE HERE #####\n",
        "\n",
        "# Compute ROC AUC scores\n",
        "train_auc = ##### CODE HERE #####\n",
        "val_auc = ##### CODE HERE #####\n",
        "\n",
        "print('ROC AUC score for the training data = {}'.format(train_auc))\n",
        "print('ROC AUC score for the validation data = {}'.format(val_auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNjJAAQGZuGS"
      },
      "source": [
        "# Part 5 - Gradient Boosted Tree: Hyperparameter Tuning\n",
        "In this section, we will:\n",
        "- Tune the gradient boosted tree model for the following hyperparameters:\n",
        "  - Number of estimators\n",
        "  - Maximum tree depth\n",
        "  - Learning rate\n",
        "- Tune the gradient boosted tree model for a combination of number of estimators, maximum tree depth and learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EUHTVsNZuGT"
      },
      "source": [
        "## Subpart 1 - Hyperparameter Tuning: Number of Estimators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlXDzY6TZuGT"
      },
      "outputs": [],
      "source": [
        "# Define a list of number of estimators to tune over\n",
        "num_estimators = np.arange(50, 550, 50)\n",
        "\n",
        "# Create and train a gradient boosted tree model for each value of number of estimators\n",
        "performance_df = pd.DataFrame(data = None)\n",
        "\n",
        "# Use a for loop to loop over the different models and capture their performances\n",
        "indexcount = -1\n",
        "for current_num_estimators in num_estimators:\n",
        "    indexcount = indexcount + 1\n",
        "    \n",
        "    # Create a gradient boosted tree model with the current specifications\n",
        "    # Use the current number of estimators, a maximum tree depth of 5, a learning rate of 0.1, and set the class weight as 'balanced'\n",
        "    # Set the random state parameter to 123\n",
        "    current_gbt = ##### CODE HERE #####\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    ##### CODE HERE #####\n",
        "    \n",
        "    print('\\n Training for {} estimators is complete'.format(current_num_estimators))\n",
        "    \n",
        "    # Obtain predictions\n",
        "    current_y_pred_train = ##### CODE HERE #####\n",
        "    current_y_pred_val = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute accuracy scores\n",
        "    current_train_acc = ##### CODE HERE #####\n",
        "    current_val_acc = ##### CODE HERE #####\n",
        "    \n",
        "    # Obtain predicted probabilities for class '1'\n",
        "    current_train_probabilities = ##### CODE HERE #####\n",
        "    current_val_probabilities = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute ROC AUC scores\n",
        "    current_train_auc = ##### CODE HERE #####\n",
        "    current_val_auc = ##### CODE HERE #####\n",
        "    \n",
        "    tempdf = pd.DataFrame(index = [indexcount],\n",
        "                          data = {'Number of Estimators': current_num_estimators,\n",
        "                                  'Training Accuracy': current_train_acc,\n",
        "                                  'Validation Accuracy': current_val_acc,\n",
        "                                  'Training ROC AUC': current_train_auc,\n",
        "                                  'Validation ROC AUC': current_val_auc})\n",
        "    \n",
        "    performance_df = pd.concat([performance_df, tempdf])\n",
        "\n",
        "performance_df.set_index('Number of Estimators')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG6xZTlrZuGT"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation accuracy scores with respect to number of estimators\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Number of Estimators', y = 'Validation Accuracy', marker = 'o', markersize = 12)\n",
        "plt.title('Validation Accuracy Scores by Number of Estimators')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.xticks(num_estimators);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2L8HJrDZuGT"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation ROC AUC scores with respect to number of estimators\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Number of Estimators', y = 'Validation ROC AUC', marker = 'o', markersize = 12)\n",
        "plt.title('Validation ROC AUC Scores by Number of Estimators')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.xlabel('Number of Estimators')\n",
        "plt.xticks(num_estimators);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDL-avB-ZuGT"
      },
      "source": [
        "## Subpart 2 - Hyperparameter Tuning: Maximum Tree Depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFx9O9TAZuGU"
      },
      "outputs": [],
      "source": [
        "# Define a list of maximum tree depth values to tune over\n",
        "max_tree_depths = np.arange(1, 11, 1)\n",
        "\n",
        "# Create and train a gradient boosted tree model for each value of maximum tree depth\n",
        "performance_df = pd.DataFrame(data = None)\n",
        "\n",
        "# Use a for loop to loop over the different models and capture their performances\n",
        "indexcount = -1\n",
        "for current_max_tree_depth in max_tree_depths:\n",
        "    indexcount = indexcount + 1\n",
        "    \n",
        "    # Create a gradient boosted tree model with the current specifications\n",
        "    # Use 100 estimators, the current maximum tree depth, a learning rate of 0.1, and set the class weight as 'balanced'\n",
        "    # Set the random state parameter to 123\n",
        "    current_gbt = ##### CODE HERE #####\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    ##### CODE HERE #####\n",
        "    \n",
        "    print('\\n Training for tree depth of {} is complete'.format(current_max_tree_depth))\n",
        "    \n",
        "    # Obtain predictions\n",
        "    current_y_pred_train = ##### CODE HERE #####\n",
        "    current_y_pred_val = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute accuracy scores\n",
        "    current_train_acc = ##### CODE HERE #####\n",
        "    current_val_acc = ##### CODE HERE #####\n",
        "    \n",
        "    # Obtain predicted probabilities for class '1'\n",
        "    current_train_probabilities = ##### CODE HERE #####\n",
        "    current_val_probabilities = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute ROC AUC scores\n",
        "    current_train_auc = ##### CODE HERE #####\n",
        "    current_val_auc = ##### CODE HERE #####\n",
        "    \n",
        "    tempdf = pd.DataFrame(index = [indexcount],\n",
        "                          data = {'Maximum Tree Depth': current_max_tree_depth,\n",
        "                                  'Training Accuracy': current_train_acc,\n",
        "                                  'Validation Accuracy': current_val_acc,\n",
        "                                  'Training ROC AUC': current_train_auc,\n",
        "                                  'Validation ROC AUC': current_val_auc})\n",
        "    \n",
        "    performance_df = pd.concat([performance_df, tempdf])\n",
        "\n",
        "performance_df.set_index('Maximum Tree Depth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwX5p7GvZuGU"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation accuracy scores with respect to maximum tree depth\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Maximum Tree Depth', y = 'Validation Accuracy', marker = 'o', markersize = 12)\n",
        "plt.title('Validation Accuracy Scores by Maximum Tree Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Maximum Tree Depth')\n",
        "plt.xticks(max_tree_depths);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPzQMFTlZuGU"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation ROC AUC scores with respect to maximum tree depth\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Maximum Tree Depth', y = 'Validation ROC AUC', marker = 'o', markersize = 12)\n",
        "plt.title('Validation ROC AUC Scores by Maximum Tree Depth')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.xlabel('Maximum Tree Depth')\n",
        "plt.xticks(max_tree_depths);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f39dFtN9ZuGU"
      },
      "source": [
        "## Subpart 3 - Hyperparameter Tuning: Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdY0SMeSZuGU"
      },
      "outputs": [],
      "source": [
        "# Define a list of learning rate values to tune over\n",
        "learning_rates = np.arange(0.02, 0.22, 0.02)\n",
        "\n",
        "# Create and train a gradient boosted tree model for each value of learning rate\n",
        "performance_df = pd.DataFrame(data = None)\n",
        "\n",
        "# Use a for loop to loop over the different models and capture their performances\n",
        "indexcount = -1\n",
        "for current_learning_rate in learning_rates:\n",
        "    indexcount = indexcount + 1\n",
        "    \n",
        "    # Create a gradient boosted tree model with the current specifications\n",
        "    # Use 100 estimators, a maximum tree depth of 5, the current learning rate, and set the class weight as 'balanced'\n",
        "    # Set the random state parameter to 123\n",
        "    current_gbt = ##### CODE HERE #####\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    ##### CODE HERE #####\n",
        "    \n",
        "    print('\\n Training for learning rate of {} is complete'.format(np.round(current_learning_rate, 2)))\n",
        "    \n",
        "    # Obtain predictions\n",
        "    current_y_pred_train = ##### CODE HERE #####\n",
        "    current_y_pred_val = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute accuracy scores\n",
        "    current_train_acc = ##### CODE HERE #####\n",
        "    current_val_acc = ##### CODE HERE #####\n",
        "    \n",
        "    # Obtain predicted probabilities for class '1'\n",
        "    current_train_probabilities = ##### CODE HERE #####\n",
        "    current_val_probabilities = ##### CODE HERE #####\n",
        "    \n",
        "    # Compute ROC AUC scores\n",
        "    current_train_auc = ##### CODE HERE #####\n",
        "    current_val_auc = ##### CODE HERE #####\n",
        "    \n",
        "    tempdf = pd.DataFrame(index = [indexcount],\n",
        "                          data = {'Learning Rate': current_learning_rate,\n",
        "                                  'Training Accuracy': current_train_acc,\n",
        "                                  'Validation Accuracy': current_val_acc,\n",
        "                                  'Training ROC AUC': current_train_auc,\n",
        "                                  'Validation ROC AUC': current_val_auc})\n",
        "    \n",
        "    performance_df = pd.concat([performance_df, tempdf])\n",
        "\n",
        "performance_df.set_index('Learning Rate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsbcHwfDZuGV"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation accuracy scores with respect to learning rate\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Learning Rate', y = 'Validation Accuracy', marker = 'o', markersize = 12)\n",
        "plt.title('Validation Accuracy Scores by Learning Rate')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.xticks(learning_rates);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoWGXUW2ZuGV"
      },
      "outputs": [],
      "source": [
        "# Visualize variation in validation ROC AUC scores with respect to learning rate\n",
        "plt.figure(figsize = (10, 4))\n",
        "\n",
        "sns.lineplot(data = performance_df, x = 'Learning Rate', y = 'Validation ROC AUC', marker = 'o', markersize = 12)\n",
        "plt.title('Validation ROC AUC Scores by Learning Rate')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.xticks(learning_rates);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K61uzx0MZuGV"
      },
      "source": [
        "## Subpart 4 - Hyperparameter Tuning: Combinations of Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "O1XAN1tuZuGV"
      },
      "outputs": [],
      "source": [
        "# Initialize a basic gradient boosted classifier model\n",
        "# Set the class weight as 'balanced'\n",
        "# Set the random state parameter to 123\n",
        "base_grid_model = ##### CODE HERE #####\n",
        "\n",
        "# Define a range of hyperparameter values to tune for and store them in a dictionary\n",
        "parameters_grid = {'n_estimators': [50, 100],\n",
        "                   'max_depth': [7, 9],\n",
        "                   'learning_rate': [0.06, 0.08]}\n",
        "\n",
        "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
        "# Use ROC AUC score as a scoring metric\n",
        "# Use the default number of cross-validation folds\n",
        "# Set the 'verbose' parameter to 3 or more to display useful results during the process\n",
        "grid = ##### CODE HERE #####\n",
        "\n",
        "# Fit the model on the training data\n",
        "grid_model = ##### CODE HERE #####\n",
        "\n",
        "# Print the optimal values of 'n_estimators', 'max_depth' and 'learning_rate'\n",
        "best_n_estimators = grid_model.best_params_['n_estimators']\n",
        "best_max_depth = grid_model.best_params_['max_depth']\n",
        "best_learning_rate = grid_model.best_params_['learning_rate']\n",
        "best_roc_auc_score = grid_model.best_score_\n",
        "\n",
        "print('\\n The optimal model has {} estimators, each of maximum tree depth {}, a learning rate of {}, and it has an ROC AUC score of {}.'.format(best_n_estimators, best_max_depth, best_learning_rate, best_roc_auc_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1sa2up7ZuGV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}